{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8901177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import snntorch as snn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c97e1d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "data_path='/tmp/data/fmnist'\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ec5beda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:00<00:00, 60.7MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 2.45MB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:00<00:00, 40.6MB/s]\n",
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 32.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "fmnist_train = datasets.FashionMNIST(data_path, train=True, download=True, transform=transform)\n",
    "fmnist_test = datasets.FashionMNIST(data_path, train=False, download=True, transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(fmnist_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(fmnist_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a1cbb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snntorch import surrogate\n",
    "\n",
    "# network parameters\n",
    "num_inputs = 28*28\n",
    "num_hidden = 128\n",
    "num_outputs = 10\n",
    "num_steps = 1\n",
    "\n",
    "# spiking neuron parameters\n",
    "beta = 0.9  # neuron decay rate\n",
    "grad = surrogate.fast_sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11b73df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Flatten(),\n",
    "                    nn.Linear(num_inputs, num_hidden),\n",
    "                    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True),\n",
    "                    nn.Linear(num_hidden, num_outputs),\n",
    "                    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True, output=True)\n",
    "                    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61b77846",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_outputs = 500\n",
    "\n",
    "net_pop = nn.Sequential(nn.Flatten(),\n",
    "                        nn.Linear(num_inputs, num_hidden),\n",
    "                        snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True),\n",
    "                        nn.Linear(num_hidden, pop_outputs),\n",
    "                        snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True, output=True)\n",
    "                        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "866e1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch.functional as SF\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=2e-3, betas=(0.9, 0.999))\n",
    "loss_fn = SF.mse_count_loss(correct_rate=1.0, incorrect_rate=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b06178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snntorch import utils\n",
    "\n",
    "def test_accuracy(data_loader, net, num_steps, population_code=False, num_classes=False):\n",
    "  with torch.no_grad():\n",
    "    total = 0\n",
    "    acc = 0\n",
    "    net.eval()\n",
    "\n",
    "    data_loader = iter(data_loader)\n",
    "    for data, targets in data_loader:\n",
    "      data = data.to(device)\n",
    "      targets = targets.to(device)\n",
    "      utils.reset(net)\n",
    "      spk_rec, _ = net(data)\n",
    "\n",
    "      if population_code:\n",
    "        acc += SF.accuracy_rate(spk_rec.unsqueeze(0), targets, population_code=True, num_classes=10) * spk_rec.size(1)\n",
    "      else:\n",
    "        acc += SF.accuracy_rate(spk_rec.unsqueeze(0), targets) * spk_rec.size(1)\n",
    "\n",
    "      total += spk_rec.size(1)\n",
    "\n",
    "  return acc/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e977e08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Test set accuracy: 59.187%\n",
      "\n",
      "Epoch: 1\n",
      "Test set accuracy: 72.033%\n",
      "\n",
      "Epoch: 2\n",
      "Test set accuracy: 65.823%\n",
      "\n",
      "Epoch: 3\n",
      "Test set accuracy: 62.342%\n",
      "\n",
      "Epoch: 4\n",
      "Test set accuracy: 64.794%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from snntorch import backprop\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    avg_loss = backprop.BPTT(net, train_loader, num_steps=num_steps,\n",
    "                          optimizer=optimizer, criterion=loss_fn, time_var=False, device=device)\n",
    "\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    print(f\"Test set accuracy: {test_accuracy(test_loader, net, num_steps)*100:.3f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45cde3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = SF.mse_count_loss(correct_rate=1.0, incorrect_rate=0.0, population_code=True, num_classes=10)\n",
    "optimizer = torch.optim.Adam(net_pop.parameters(), lr=2e-3, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3328cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Test set accuracy: 79.747%\n",
      "\n",
      "Epoch: 1\n",
      "Test set accuracy: 80.053%\n",
      "\n",
      "Epoch: 2\n",
      "Test set accuracy: 81.230%\n",
      "\n",
      "Epoch: 3\n",
      "Test set accuracy: 83.060%\n",
      "\n",
      "Epoch: 4\n",
      "Test set accuracy: 82.595%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    avg_loss = backprop.BPTT(net_pop, train_loader, num_steps=num_steps,\n",
    "                            optimizer=optimizer, criterion=loss_fn, time_var=False, device=device)\n",
    "\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    print(f\"Test set accuracy: {test_accuracy(test_loader, net_pop, num_steps, population_code=True, num_classes=10)*100:.3f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dc4e8e",
   "metadata": {},
   "source": [
    "# Own implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c39adaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "loss 2.885247600844469\n",
      "train accuracy 0.1662579695929377\n",
      "test accuracy 28.48939929328622\n",
      "Epoch: 1\n",
      "loss 2.682589676521642\n",
      "train accuracy 0.2697400686611084\n",
      "test accuracy 37.014134275618375\n",
      "Epoch: 2\n",
      "loss 2.599637602286458\n",
      "train accuracy 0.42116233447768514\n",
      "test accuracy 45.75971731448763\n"
     ]
    }
   ],
   "source": [
    "from neural_nets.configurable_spiking_neural_net import ConfigurableSpikingNeuralNet\n",
    "from constants import NUMBER_INPUT_NEURONS, NUMBER_HIDDEN_LAYERS, NUMBER_HIDDEN_NEURONS, NUMBER_OUTPUT_NEURONS, BETA, THRESHOLD, TIME_STEPS, DEVICE\n",
    "from training.train_simplified_snn import train_simplified_snn\n",
    "\n",
    "net = ConfigurableSpikingNeuralNet(number_input_neurons=NUMBER_INPUT_NEURONS, \n",
    "                                           number_hidden_neurons=NUMBER_HIDDEN_NEURONS,\n",
    "                                           number_hidden_layers=NUMBER_HIDDEN_LAYERS,\n",
    "                                           number_output_neurons=NUMBER_OUTPUT_NEURONS, \n",
    "                                           beta=BETA, \n",
    "                                           threshold=THRESHOLD,\n",
    "                                           time_steps=TIME_STEPS, \n",
    "                                           sparsity=0,\n",
    "                                           population_coding=False).to(DEVICE)\n",
    "\n",
    "#train_simplified_snn(net, num_epochs='early_stopping', loss_configuration='membrane_potential_cross_entropy')\n",
    "train_simplified_snn(net, num_epochs='early_stopping', \n",
    "                     loss_configuration='rate_code_cross_entropy', \n",
    "                     output_file_path='./output/experiments_population_coding/rate_code_cross_entropy.json',\n",
    "                     save_plots=f'./output/experiments_population_coding/rate_code_cross_entropy')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whk-snn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
